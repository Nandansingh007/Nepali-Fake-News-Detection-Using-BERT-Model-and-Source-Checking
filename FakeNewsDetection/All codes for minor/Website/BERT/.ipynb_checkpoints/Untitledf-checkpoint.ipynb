{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a07191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import tensorflow_text as text\n",
    "from transformers import TFBertModel\n",
    "from ScrapeSearchEngine.SearchEngine import Google\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c439120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "#Loading trained moddel\n",
    "loaded_model = tf.keras.models.load_model(\"model2.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8156e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing text\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
    "# encoder_inputs = preprocessor(text_input)\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\",trainable=False)\n",
    "\n",
    "def get_sentence_embeding(sentences):\n",
    "  preprocessed_text = bert_preprocess(sentences)\n",
    "  return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17d13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words\n",
    "import re\n",
    "\n",
    "with open('stopwords_new.txt', 'r',  encoding='utf-8') as file:\n",
    "    stop = file.read()\n",
    "    \n",
    "def preprocessing(text):\n",
    "    \n",
    "    #punctuation removal\n",
    "    text_punctuation = re.sub(r'[।?:;\\'\",.\\n&—‘’“”!()-]', '', text)\n",
    "    \n",
    "    \n",
    "    stopwords = []\n",
    "    for word in stop.split():\n",
    "        stopwords.append(word)\n",
    "        \n",
    "   \n",
    "    \n",
    "    text1 = text_punctuation\n",
    "    \n",
    "\n",
    "    str_temp = \"\"\n",
    "    for words in text1.split():\n",
    "      # checking if the word is not in the stopword file\n",
    "      if str(words) not in stopwords:\n",
    "        # adding the words that is not in stopword file to the str_temp \n",
    "        str_temp += words\n",
    "        str_temp += \" \"\n",
    "\n",
    "    #result after removing stopwords\n",
    "    return str_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:07] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:08] \"GET /static/photos/image1.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:08] \"GET /static/photos/image2.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:08] \"GET /static/photos/fakenews.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:08] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /home [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connection.py\", line 414, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1071, in _create\n",
      "    self.do_handshake()\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\adhip\\AppData\\Local\\Temp\\ipykernel_19724\\4066734427.py\", line 28, in predicting_news\n",
      "    page = requests.get(url)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 563, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:24] \"\u001b[35m\u001b[1mPOST /home HTTP/1.1\u001b[0m\" 500 -\n",
      "ERROR:__main__:Exception on /home [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connection.py\", line 414, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1071, in _create\n",
      "    self.do_handshake()\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\adhip\\AppData\\Local\\Temp\\ipykernel_19724\\4066734427.py\", line 28, in predicting_news\n",
      "    page = requests.get(url)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 563, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:31] \"\u001b[35m\u001b[1mPOST /home HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:46] \"GET /check_news HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:46] \"\u001b[36mGET /static/photos/fakenews.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:46] \"\u001b[36mGET /static/photos/image1.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:21:46] \"\u001b[36mGET /static/photos/image2.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:01] \"POST /check HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:01] \"\u001b[36mGET /static/photos/fakenews.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:01] \"\u001b[36mGET /static/photos/image1.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:01] \"\u001b[36mGET /static/photos/image2.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar titles:  ['समिति सभापति र संक्रमणकालीन विधेयकबारे तीन दलबीच सहमति']\n",
      "Trusted websites:  ['https://ekantipur.com/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:04] \"POST /source HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:04] \"\u001b[36mGET /static/photos/fakenews.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:04] \"\u001b[36mGET /static/photos/image2.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:04] \"\u001b[36mGET /static/photos/image1.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:45] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:45] \"GET /static/photos/image1.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:45] \"GET /static/photos/image2.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:45] \"\u001b[36mGET /static/photos/fakenews.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /home [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connection.py\", line 414, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1071, in _create\n",
      "    self.do_handshake()\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\adhip\\AppData\\Local\\Temp\\ipykernel_19724\\4066734427.py\", line 28, in predicting_news\n",
      "    page = requests.get(url)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 563, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /news/2023/05/14/16840551082532638.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:54] \"\u001b[35m\u001b[1mPOST /home HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:22:54] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:23:43] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /home [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connection.py\", line 414, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1071, in _create\n",
      "    self.do_handshake()\n",
      "  File \"D:\\Python\\lib\\ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"D:\\Python\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /pradesh-5/2023/05/14/168405598436239488.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Python\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\adhip\\AppData\\Local\\Temp\\ipykernel_19724\\4066734427.py\", line 28, in predicting_news\n",
      "    page = requests.get(url)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Python\\lib\\site-packages\\requests\\adapters.py\", line 563, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='ekantipur.com', port=443): Max retries exceeded with url: /pradesh-5/2023/05/14/168405598436239488.html (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:23:59] \"\u001b[35m\u001b[1mPOST /home HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:24:23] \"POST /home HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:24:23] \"GET /static/photos/image2.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:24:23] \"GET /static/photos/image1.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [14/May/2023 15:24:23] \"\u001b[36mGET /static/photos/fakenews.jpg HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from flask import Flask, request, render_template, session\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "from flask import make_response\n",
    "from flask import jsonify\n",
    "from newspaper import Article\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "news_ss = []\n",
    "Prediction = ''\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/home', methods=['GET', 'POST'])\n",
    "\n",
    "\n",
    "def predicting_news():\n",
    "    # Check if the submit button was pressed and extract the submitted URL from the form\n",
    "    if request.form.get('submit'):\n",
    "        url = request.form.get('url')\n",
    "    # Use the requests library to get the HTML content of the page from the submitted URL\n",
    "    page = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup and extract all the text from the <p> tags\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    text = ''\n",
    "    for p in soup.find_all('p'):\n",
    "        text += p.text\n",
    "\n",
    "    # Split the text into words and limit the number of words to 600\n",
    "    words = text.split()\n",
    "    if len(words) > 600:\n",
    "        words = words[:600]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    # Use the newspaper3k library to download and parse the article to extract the title, publish date, and authors\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    title = article.title\n",
    "    publish_date = article.publish_date\n",
    "    authors = article.authors\n",
    "\n",
    "    # Define some string constants to use as labels for the data to be displayed in the HTML template\n",
    "    Titles = 'Titles'\n",
    "    Description = 'Description'\n",
    "    Date = 'Date'\n",
    "    Author = 'Author'\n",
    "\n",
    "    # Render the HTML template, passing in the extracted data as variables\n",
    "    return render_template('index.html',title = title,Titles=Titles,text = text,Description = Description,Date = Date,publish_date = publish_date,authors = authors, Author = Author)\n",
    "\n",
    "\n",
    "@app.route('/check_news')\n",
    "def check():\n",
    "    \n",
    "    return render_template('check_news.html')\n",
    "\n",
    "@app.route('/about')\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route('/contact')\n",
    "def contact():\n",
    "    \n",
    "    return render_template('contact.html')\n",
    "@app.route('/check', methods=['GET', 'POST'])\n",
    "\n",
    "def check_news():\n",
    "    # Check if the check button was pressed and extract the submitted news title from the form\n",
    "    if request.form.get('check'):\n",
    "    # Define a user agent string for making HTTP requests\n",
    "        userAgent = ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3')\n",
    "        # Extract the news title submitted in the form\n",
    "        news_title = request.form.get('title')\n",
    "        # Clear the global list variable 'news_ss' which will store the cosine similarity scores of the searched news with other news articles\n",
    "        global news_ss\n",
    "        news_ss.clear()\n",
    "        # Initialize an empty list to store the links of the search results\n",
    "        non_base_links = []\n",
    "        # Use the Google function to search for the news article based on the title\n",
    "        search = news_title\n",
    "        googleText, googleLink = Google(search, userAgent)\n",
    "        # Initialize empty lists to store non-similar titles, similar titles, and base URLs of the search results\n",
    "        non_similar_titles=[]\n",
    "        googleLinks = googleLink\n",
    "        title_similarw = []\n",
    "        base_urls = []\n",
    "        # Extract the base URL and non-base URL links from the search results\n",
    "        for link in googleLinks:\n",
    "            parsed_uri = urlparse(link)\n",
    "            base_url = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "            base_urls.append(base_url)\n",
    "            non_base_links.append(link)\n",
    "        \n",
    "        # Define cosine similarity function to calculate the cosine similarity between two vectors\n",
    "        def cosine_similarity(a, b):\n",
    "            dot_product = np.dot(a, b)\n",
    "            norm_a = np.linalg.norm(a)\n",
    "            norm_b = np.linalg.norm(b)\n",
    "            return dot_product / (norm_a * norm_b)\n",
    "        \n",
    "        # Define Jaccard similarity function to calculate the Jaccard similarity between two sets\n",
    "        def jaccard_similarity(a, b):\n",
    "            seta = set(a)\n",
    "            setb = set(b)\n",
    "            intersection = seta.intersection(setb)\n",
    "            union = seta.union(setb)\n",
    "            return len(intersection)/ len(union)\n",
    "\n",
    "        # Find the cosine similarity between two titles using BERT\n",
    "        def cosine_similarity_using_bert(title1, title2):\n",
    "            # Preprocess the two titles using BERT preprocessor\n",
    "            title1_encoded = get_sentence_embeding([title1])[0]\n",
    "            title2_encoded = get_sentence_embeding([title2])[0]\n",
    "\n",
    "            # Compute the cosine similarity between the encoded titles\n",
    "            similarity = cosine_similarity(title1_encoded, title2_encoded)\n",
    "            return similarity\n",
    "\n",
    "        # The title which is used to compare the similarity between all the searched results\n",
    "        query_title = search\n",
    "\n",
    "        # The list of searched results\n",
    "        news_titles = googleText\n",
    "\n",
    "        # The list of trusted websites\n",
    "        trusted_websites = [\"https://ekantipur.com/\", \"https://annapurnapost.com/\", \"https://www.onlinekhabar.com/\",\n",
    "                            \"https://gorkhapatraonline.com/\", \"https://www.setopati.com/\",\n",
    "                            \"https://www.ratopati.com/category/main-news\", \"https://nagariknews.nagariknetwork.com/\",\n",
    "                            \"https://www.nayapatrikadaily.com/\", \"https://www.bbc.com/nepali\"]\n",
    "\n",
    "        # List to store the similar news title\n",
    "        similar_titles = []\n",
    "\n",
    "        # Iterating over each searched result to check the similarity\n",
    "        for i, title in enumerate(news_titles):\n",
    "            # Compute the cosine similarity between the query title and the current title\n",
    "            sim,jac_sim = cosine_similarity_using_bert(query_title, title),jaccard_similarity(query_title,title)\n",
    "            if sim >= 0.7 and jac_sim>=0.6:\n",
    "                title_similarw.append(title)\n",
    "                non_similar_titles.append(non_base_links[i])\n",
    "                # Check if the news is from trusted website\n",
    "                if base_urls[i] in trusted_websites:\n",
    "                    # Adding the news title to the list if the similarity is greater than 0.7 and news is from trusted website\n",
    "                    similar_titles.append(title)\n",
    "\n",
    "        # Printing the list of similar news titles\n",
    "        print(\"Similar titles: \", similar_titles)\n",
    "        \n",
    "        news_ss.extend(non_similar_titles)\n",
    "        \n",
    "        # List to store the trusted websites\n",
    "        trusted_websites_list = []\n",
    "\n",
    "        # Iterating over each news title\n",
    "        for title in similar_titles:\n",
    "            # Finding the index of the title in the list of searched results\n",
    "            index = news_titles.index(title)\n",
    "\n",
    "            # Adding the base URL to the list of trusted websites\n",
    "            trusted_websites_list.append(base_urls[index])\n",
    "\n",
    "        # Printing the list of trusted websites where the news is available\n",
    "        print(\"Trusted websites: \", trusted_websites_list)\n",
    "        global Prediction\n",
    "        if len(similar_titles) != 0 and len(trusted_websites_list) != 0:\n",
    "            \n",
    "            Prediction = \"True News\"\n",
    "            return render_template('check_news.html',Prediction = Prediction)\n",
    "        else:\n",
    "            \n",
    "            Prediction = \"News not found on trusted websites. Please enter the news description and click the predict button to run BERT model and to check authenticity of the news.\"\n",
    "            return render_template('check_news.html',Prediction = Prediction)\n",
    "\n",
    "        \n",
    "@app.route('/source', methods=['POST'])\n",
    "def source89():\n",
    "    if request.form.get('source'):\n",
    "        \n",
    "        return render_template('check_news.html',Prediction = Prediction,news_ss = news_ss)\n",
    "        \n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_news():\n",
    "    if request.form.get('predict'):\n",
    "      news_description = request.form.get('description')\n",
    "      news_description1 = preprocessing(news_description)  \n",
    "    def get_prediction(news_description):\n",
    "        probability = loaded_model.predict([news_description])\n",
    "        \n",
    "        if probability[0][0] > 0.5:\n",
    "            Prediction = \"Fake News\"\n",
    "        else:\n",
    "            Prediction = \"True News\"\n",
    "        return render_template('check_news.html',Prediction = Prediction)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return get_prediction(news_description)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53851294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd3438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
